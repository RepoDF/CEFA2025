{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6c9acc36",
      "metadata": {},
      "source": [
        "  <a target=\"_blank\" href=\"https://colab.research.google.com/github/intro-stat-learning/ISLP_labs/blob/v2.2/Ch10-deeplearning-lab.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "  </a>\n",
        "\n",
        "  [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/intro-stat-learning/ISLP_labs/v2.2?labpath=Ch10-deeplearning-lab.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6pPJrwWf9zhf",
      "metadata": {
        "id": "6pPJrwWf9zhf"
      },
      "source": [
        "\n",
        "### Aprendizaje Profundo\n",
        "\n",
        "Ejemplo red neuronal simple.\n",
        "\n",
        "Podemos entonces introducir el ejemplo más directo de red neuronal que se trata del modelo logit, como lo revisamos en las notas de clase. Para ello vamos a usar una base de datos bastante popularizada que se trata de la base de datos de mnist la cuál fue compilada por Yann Le Cun entre otros expertos en AI.\n",
        "\n",
        "La idea de esta base de datos es poder clasificar los dígitos manuscritos. Entre las siguientes opciones: (0,1,2,3,4,5,6,7,8,9). Para ello primero debemos instalar algunas librerías complementarias para el trabajo de ciencia de datos. \n",
        "\n",
        "La siguiente implementación de una red neuronal simple esta basado en la implementación presentada en el documento building a logistic regresison: https://machinelearningmastery.com/building-a-logistic-regression-classifier-in-pytorch/. La cuál hace una implementación más directa de la regresión logística.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "nCY8pS6V_5rB",
      "metadata": {
        "id": "nCY8pS6V_5rB"
      },
      "outputs": [],
      "source": [
        "# %pip install torchmetrics\n",
        "# %pip install torchinfo\n",
        "# %pip install ISLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "WPxeR1tVBnRf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPxeR1tVBnRf",
        "outputId": "42fb0f45-7ac4-4f70-b3e3-accb5ea40bf4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 0\n"
          ]
        }
      ],
      "source": [
        "### Importamos las librerias de Pytorch.\n",
        "import os\n",
        "import numpy as np, pandas as pd\n",
        "from matplotlib.pyplot import subplots\n",
        "from sklearn.linear_model import \\\n",
        "     (LinearRegression,\n",
        "      LogisticRegression,\n",
        "      Lasso)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from ISLP import load_data\n",
        "from ISLP.models import ModelSpec as MS\n",
        "from sklearn.model_selection import \\\n",
        "     (train_test_split,\n",
        "      GridSearchCV)\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import RMSprop\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "from torchmetrics import (MeanAbsoluteError,\n",
        "                          R2Score)\n",
        "from torchinfo import summary\n",
        "\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "\n",
        "from pytorch_lightning import seed_everything\n",
        "seed_everything(0, workers=True)\n",
        "torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "\n",
        "from torchvision.io import read_image\n",
        "from torchvision.datasets import MNIST, CIFAR100\n",
        "from torchvision.models import (resnet50,\n",
        "                                ResNet50_Weights)\n",
        "from torchvision.transforms import (Resize,\n",
        "                                    Normalize,\n",
        "                                    CenterCrop,\n",
        "                                    ToTensor)\n",
        "from ISLP.torch import (SimpleDataModule,\n",
        "                        SimpleModule,\n",
        "                        ErrorTracker,\n",
        "                        rec_num_workers)\n",
        "\n",
        "from ISLP.torch.imdb import (load_lookup,\n",
        "                             load_tensor,\n",
        "                             load_sparse,\n",
        "                             load_sequential)\n",
        "\n",
        "from glob import glob\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "e742c241",
      "metadata": {},
      "outputs": [],
      "source": [
        "path = os.path.dirname(os.getcwd())\n",
        "\n",
        "if path == '/': # Si estamos en la raíz del sistema, entonces no es necesario agregar la carpeta datos. (Aplica en Google Colab)\n",
        "    file_path = os.path.join('datos', 'forex_data.csv')\n",
        "else:\n",
        "    file_path = os.path.join(path,'datos', 'forex_data.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "IOx61ZxDCCyz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOx61ZxDCCyz",
        "outputId": "b7a463ab-6b08-4577-c6f0-09b9ba8b1581"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(mnist_train,\n",
        " mnist_test) = [MNIST(root='data',\n",
        "                      train=train,\n",
        "                      download=True,\n",
        "                      transform=ToTensor())\n",
        "                for train in [True, False]]\n",
        "mnist_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "kH20r_13ChIG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "kH20r_13ChIG",
        "outputId": "6f52b945-84cb-4df5-90a6-3d07dd108421"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "###\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "##3 Podemos ver entonces una ejemplo del digito manuscrito.\n",
        "img_5 = mnist_train[1][0].numpy().reshape(28, 28)\n",
        "plt.imshow(img_5, cmap='gray')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yPwNEQ8zCz7S",
      "metadata": {
        "id": "yPwNEQ8zCz7S"
      },
      "source": [
        "Podemos entonces cargar los datos usando la función load Dataset con la función DataLoader con el objetivo de cargar los datos al modelo en Batches o Lotes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "c0w-WF1vC8pl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0w-WF1vC8pl",
        "outputId": "30b96a72-0c4b-4769-8756-502daa1c7689"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x250500af370>"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Let's do it with a batch size of 32.\n",
        "batch_size_1 = 32\n",
        "train_loader = DataLoader(dataset = mnist_train, batch_size = batch_size_1, shuffle = True)\n",
        "train_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "wbTlPpoHDtK8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbTlPpoHDtK8",
        "outputId": "fa758377-8452-405d-ac81-aa1ddaf5fbbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(\n",
              "  (linear): Linear(in_features=784, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Vamos entonces a definir una red neuronal heredando de la clase de nn.Module para definir un modelo de Regresión Logísticas.\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, n_inputs, n_outputs):\n",
        "        ### El método de súper se aplica en este caso para que la clase herede los métodos de clase padre. \n",
        "        super(LogisticRegression, self).__init__()\n",
        "        ## En este caso incluirmos una capa oculta que toma n_inputs y produce n_outputs.\n",
        "        self.linear = torch.nn.Linear(n_inputs, n_outputs)\n",
        "    # make predictions\n",
        "  def forward(self, x):\n",
        "        ## Finalmente para genear los resultados de aplicar la red aplicamos la función sigmoide.\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "### En este caso instanciamos la clase con los métodos del constructor los cuáles requiren unos n_inputs de tamaño 28x28 . \n",
        "### y n_outputs de 10 dígitos que se produciran. \n",
        "n_inputs = 28*28\n",
        "n_outputs = 10\n",
        "\n",
        "log_regr = LogisticRegression(n_inputs, n_outputs)\n",
        "log_regr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vFIX6OwwFCjb",
      "metadata": {
        "id": "vFIX6OwwFCjb"
      },
      "source": [
        "### Entrenamos el clasificador.\n",
        "\n",
        "La red neuronal se puede entrenar con varias funciones dependiendo de la característica del output. Existen fundamentalmente dos: \n",
        "\n",
        "(1) El MSE. Para casos de Regresión.  \n",
        "\n",
        "En el caso de la función de MSE su definición era la siguiente: \n",
        "\n",
        "$R_{i}(\\theta) = \\Sigma_{i = 1}^{N} (y_{i}-f_{\\theta} (x_{i}))$ \n",
        "\n",
        "(2) La función de Cross Entropía. Para el problema particular de Clasificación que estamos queriendo resolver se define de la siguiente manera: \n",
        "\n",
        "$R_{i}(\\theta) = -\\Sigma_{i=1}^{n} \\Sigma_{i=1}^{9} y_{im}log(f_{m}(x_{i})) $ \n",
        "\n",
        "Particularmente en la librería de PyTorch podemos definir dicha optimización siempre teniendo presentes el parámetro de backpropagation. \n",
        "\n",
        "El cuál podemos recuperar de las notas de clase, constituye la magnitud del cambio en los parámetros en dirección del gradiente.\n",
        "\n",
        "$\\theta^{m} = \\theta^{m+1} - \\rho\\nabla R(\\theta^{m}) $ \n",
        "\n",
        "Con base en la implementación presentado por Hastie, Tibshirani et Al. Mostramos entonces una implementación de una red neuronal de múltiples capas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "uQakX2SdE08N",
      "metadata": {
        "id": "uQakX2SdE08N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0. Loss: 2.2104101181030273. Accuracy: 61.07\n",
            "Epoch: 1. Loss: 2.1061415672302246. Accuracy: 72.57\n",
            "Epoch: 2. Loss: 2.0380632877349854. Accuracy: 76.57\n",
            "Epoch: 3. Loss: 2.021063804626465. Accuracy: 78.7\n",
            "Epoch: 4. Loss: 1.9599621295928955. Accuracy: 80.1\n",
            "Epoch: 5. Loss: 1.9122592210769653. Accuracy: 80.93\n",
            "Epoch: 6. Loss: 1.9080702066421509. Accuracy: 81.45\n",
            "Epoch: 7. Loss: 1.8631993532180786. Accuracy: 81.87\n",
            "Epoch: 8. Loss: 1.8526206016540527. Accuracy: 82.21\n",
            "Epoch: 9. Loss: 1.8818299770355225. Accuracy: 82.56\n",
            "Epoch: 10. Loss: 1.837859869003296. Accuracy: 82.76\n",
            "Epoch: 11. Loss: 1.7677162885665894. Accuracy: 83.1\n",
            "Epoch: 12. Loss: 1.833802342414856. Accuracy: 83.38\n",
            "Epoch: 13. Loss: 1.821901798248291. Accuracy: 83.56\n",
            "Epoch: 14. Loss: 1.7801607847213745. Accuracy: 83.65\n",
            "Epoch: 15. Loss: 1.7475173473358154. Accuracy: 83.82\n",
            "Epoch: 16. Loss: 1.8237555027008057. Accuracy: 84.09\n",
            "Epoch: 17. Loss: 1.7580866813659668. Accuracy: 84.21\n",
            "Epoch: 18. Loss: 1.77474844455719. Accuracy: 84.31\n",
            "Epoch: 19. Loss: 1.7162127494812012. Accuracy: 84.47\n",
            "Epoch: 20. Loss: 1.7484067678451538. Accuracy: 84.62\n",
            "Epoch: 21. Loss: 1.806355357170105. Accuracy: 84.75\n",
            "Epoch: 22. Loss: 1.7720530033111572. Accuracy: 84.86\n",
            "Epoch: 23. Loss: 1.7510758638381958. Accuracy: 84.99\n",
            "Epoch: 24. Loss: 1.7071735858917236. Accuracy: 85.08\n",
            "Epoch: 25. Loss: 1.7299977540969849. Accuracy: 85.12\n",
            "Epoch: 26. Loss: 1.7439159154891968. Accuracy: 85.2\n",
            "Epoch: 27. Loss: 1.746443271636963. Accuracy: 85.3\n",
            "Epoch: 28. Loss: 1.7207399606704712. Accuracy: 85.36\n",
            "Epoch: 29. Loss: 1.7525583505630493. Accuracy: 85.45\n",
            "Epoch: 30. Loss: 1.7110223770141602. Accuracy: 85.5\n",
            "Epoch: 31. Loss: 1.7109240293502808. Accuracy: 85.55\n",
            "Epoch: 32. Loss: 1.6799440383911133. Accuracy: 85.62\n",
            "Epoch: 33. Loss: 1.7226901054382324. Accuracy: 85.68\n",
            "Epoch: 34. Loss: 1.7341773509979248. Accuracy: 85.75\n",
            "Epoch: 35. Loss: 1.710544228553772. Accuracy: 85.8\n",
            "Epoch: 36. Loss: 1.7118587493896484. Accuracy: 85.83\n",
            "Epoch: 37. Loss: 1.7245962619781494. Accuracy: 85.9\n",
            "Epoch: 38. Loss: 1.7246283292770386. Accuracy: 85.96\n",
            "Epoch: 39. Loss: 1.6934725046157837. Accuracy: 85.98\n",
            "Epoch: 40. Loss: 1.7182896137237549. Accuracy: 86.03\n",
            "Epoch: 41. Loss: 1.7893950939178467. Accuracy: 86.06\n",
            "Epoch: 42. Loss: 1.8016310930252075. Accuracy: 86.12\n",
            "Epoch: 43. Loss: 1.716361403465271. Accuracy: 86.2\n",
            "Epoch: 44. Loss: 1.7235432863235474. Accuracy: 86.22\n",
            "Epoch: 45. Loss: 1.6942178010940552. Accuracy: 86.25\n",
            "Epoch: 46. Loss: 1.7549442052841187. Accuracy: 86.33\n",
            "Epoch: 47. Loss: 1.7549569606781006. Accuracy: 86.38\n",
            "Epoch: 48. Loss: 1.7349019050598145. Accuracy: 86.43\n",
            "Epoch: 49. Loss: 1.6692619323730469. Accuracy: 86.45\n"
          ]
        }
      ],
      "source": [
        "### Definimos entonces el algoritmo de optimización que será el de SGD. \n",
        "optimizer = torch.optim.SGD(log_regr.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "### Definimos el número de epochs que serán implementados en el modelo. \n",
        "epochs = 50\n",
        "### Adicionalmente con propositos explicativos reservamos los valores de la función de perdida en la lista loss. \n",
        "Loss = []\n",
        "### También reservamos el accuracy de cada modelo. \n",
        "acc = []\n",
        "for epoch in range(epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = log_regr(images.view(-1, 28*28))\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Loss.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    Loss.append(loss.item())\n",
        "    correct = 0\n",
        "    for images, labels in mnist_test:\n",
        "        outputs = log_regr(images.view(-1, 28*28))\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct += (predicted == labels).sum()\n",
        "    accuracy = 100 * (correct.item()) / len(mnist_test)\n",
        "    acc.append(accuracy)\n",
        "    print('Epoch: {}. Loss: {}. Accuracy: {}'.format(epoch, loss.item(), accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "74pwnWyvCGZB",
      "metadata": {
        "id": "74pwnWyvCGZB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X:  torch.Size([256, 1, 28, 28])\n",
            "Y:  torch.Size([256])\n",
            "X:  torch.Size([256, 1, 28, 28])\n",
            "Y:  torch.Size([256])\n"
          ]
        }
      ],
      "source": [
        "max_num_workers = rec_num_workers()\n",
        "mnist_dm = SimpleDataModule(mnist_train,\n",
        "                            mnist_test,\n",
        "                            validation=0.2,\n",
        "                            num_workers=max_num_workers,\n",
        "                            batch_size=256)\n",
        "\n",
        "mnist_dm\n",
        "\n",
        "### El siguiente método separa las variables de respuesta de las variables de entrada. \n",
        "for idx, (X_ ,Y_) in enumerate(mnist_dm.train_dataloader()):\n",
        "    print('X: ', X_.shape)\n",
        "    print('Y: ', Y_.shape)\n",
        "    if idx >= 1:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "KNL_ad-0CF7H",
      "metadata": {
        "id": "KNL_ad-0CF7H"
      },
      "outputs": [],
      "source": [
        "### Procedemos entonces con el resto de parametros "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64b60868",
      "metadata": {},
      "source": [
        "Procedemos entonces con la definición de la clase MNIST model para la implementación de una red neuronal de múltiples capas. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "6323832b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MNISTModel(\n",
              "  (layer1): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=784, out_features=256, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.4, inplace=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              "  (_forward): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Flatten(start_dim=1, end_dim=-1)\n",
              "      (1): Linear(in_features=784, out_features=256, bias=True)\n",
              "      (2): ReLU()\n",
              "      (3): Dropout(p=0.4, inplace=False)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Dropout(p=0.3, inplace=False)\n",
              "    )\n",
              "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MNISTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTModel, self).__init__()\n",
        "        ### En la primera capa se hace una codificación de 28 x 28 a una codificación de un output de 256\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28*28, 256),\n",
        "            # Se introduce una regularización no lineal.\n",
        "            nn.ReLU(),\n",
        "            # Se introduce un dropout aleatorio del 40% de las redes. \n",
        "            nn.Dropout(0.4))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            # Se introduce una segunda capa que procesa el output de 256 y lo procesa en output de 128 unidades.. \n",
        "            nn.Linear(256, 128),\n",
        "            # Se introduce una regularización no lineal\n",
        "            nn.ReLU(),\n",
        "            # Se introduce un dropout aleatorio del 30% de las undidades. \n",
        "            nn.Dropout(0.3))\n",
        "        self._forward = nn.Sequential(\n",
        "            # Por último se define que se generan los outputs de la primera capa que alimenatan a su vez los outputs de la segunda capa. \n",
        "            self.layer1,\n",
        "            self.layer2,\n",
        "            # Se comprime finalmente el output de la segunda parte en los 10 dígitos que se debía codificar. \n",
        "            nn.Linear(128, 10))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self._forward(x)\n",
        "\n",
        "### En este caso no dejamos la flexibilidad del número de inputs y del número de outputs que puede generar. \n",
        "mnist_model = MNISTModel()\n",
        "mnist_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "32ae0f24",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([256, 10])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mnist_model(X_).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "c4a0e253",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
              "===================================================================================================================\n",
              "MNISTModel                               [256, 1, 28, 28]          [256, 10]                 --\n",
              "├─Sequential: 1-1                        [256, 1, 28, 28]          [256, 10]                 --\n",
              "│    └─Sequential: 2-1                   [256, 1, 28, 28]          [256, 256]                --\n",
              "│    │    └─Flatten: 3-1                 [256, 1, 28, 28]          [256, 784]                --\n",
              "│    │    └─Linear: 3-2                  [256, 784]                [256, 256]                200,960\n",
              "│    │    └─ReLU: 3-3                    [256, 256]                [256, 256]                --\n",
              "│    │    └─Dropout: 3-4                 [256, 256]                [256, 256]                --\n",
              "│    └─Sequential: 2-2                   [256, 256]                [256, 128]                --\n",
              "│    │    └─Linear: 3-5                  [256, 256]                [256, 128]                32,896\n",
              "│    │    └─ReLU: 3-6                    [256, 128]                [256, 128]                --\n",
              "│    │    └─Dropout: 3-7                 [256, 128]                [256, 128]                --\n",
              "│    └─Linear: 2-3                       [256, 128]                [256, 10]                 1,290\n",
              "===================================================================================================================\n",
              "Total params: 235,146\n",
              "Trainable params: 235,146\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 60.20\n",
              "===================================================================================================================\n",
              "Input size (MB): 0.80\n",
              "Forward/backward pass size (MB): 0.81\n",
              "Params size (MB): 0.94\n",
              "Estimated Total Size (MB): 2.55\n",
              "==================================================================================================================="
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(mnist_model,\n",
        "        input_data=X_,\n",
        "        col_names=['input_size',\n",
        "                   'output_size',\n",
        "                   'num_params'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "58c65b61",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name  | Type             | Params | Mode \n",
            "---------------------------------------------------\n",
            "0 | model | MNISTModel       | 235 K  | train\n",
            "1 | loss  | CrossEntropyLoss | 0      | train\n",
            "---------------------------------------------------\n",
            "235 K     Trainable params\n",
            "0         Non-trainable params\n",
            "235 K     Total params\n",
            "0.941     Total estimated model params size (MB)\n",
            "13        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
          ]
        }
      ],
      "source": [
        "mnist_dm = SimpleDataModule(mnist_train,\n",
        "                            mnist_test,\n",
        "                            validation=0.2,\n",
        "                            num_workers=max_num_workers,\n",
        "                            batch_size=256)\n",
        "### Definimos entonces un CSVLogger con la intención de reservar los outputs del CSV. \n",
        "\n",
        "\n",
        "### Definimos entonces el objeto entrenador instanciado con base en el método de mnist_logger que definimos., \n",
        "### \n",
        "mnist_logger = CSVLogger('logs', name='MNIST')\n",
        "\n",
        "mnist_trainer = Trainer(deterministic=True,\n",
        "                        max_epochs=30,\n",
        "                        logger=mnist_logger,\n",
        "                        enable_progress_bar=False,\n",
        "                        callbacks=[ErrorTracker()])\n",
        "\n",
        "\n",
        "\n",
        "mnist_module = SimpleModule.classification(mnist_model,\n",
        "                                           num_classes=10)\n",
        "\n",
        "\n",
        "### Entrenamos entonces el modelo. \n",
        "mnist_trainer.fit(mnist_module,\n",
        "                  datamodule=mnist_dm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "ce1989ec",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "      test_accuracy         0.9571999907493591\n",
            "        test_loss           0.17949163913726807\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'test_loss': 0.17949163913726807, 'test_accuracy': 0.9571999907493591}]"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mnist_trainer.test(mnist_module,\n",
        "                   datamodule=mnist_dm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "49991c2a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'logs\\\\MNIST\\\\version_5\\\\metrics.csv'"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mnist_logger.experiment.metrics_file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "b6bb9d49",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\jcamargo\\\\OneDrive - FLAR\\\\Documentos\\\\CEFA_Repo_2025_Office\\\\CEFA2025'"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "c7f130f9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### Recibimos los datos registrados en el csv. \n",
        "mnist_results = pd.read_csv(os.path.join(path, \"Colab\", mnist_logger.experiment.metrics_file_path))\n",
        "fig, ax = subplots(1, 1, figsize=(6, 6))\n",
        "\n",
        "### Usamos una función para encontrar el gráfico con la evolución de los errores de validación y de entrenamiento. \n",
        "\n",
        "def summary_plot(results,\n",
        "                 ax,\n",
        "                 col='loss',\n",
        "                 valid_legend='Validation',\n",
        "                 training_legend='Training',\n",
        "                 ylabel='Loss',\n",
        "                 fontsize=20):\n",
        "    for (column,\n",
        "         color,\n",
        "         label) in zip([f'train_{col}_epoch',\n",
        "                        f'valid_{col}'],\n",
        "                       ['black',\n",
        "                        'red'],\n",
        "                       [training_legend,\n",
        "                        valid_legend]):\n",
        "        results.plot(x='epoch',\n",
        "                     y=column,\n",
        "                     label=label,\n",
        "                     marker='o',\n",
        "                     color=color,\n",
        "                     ax=ax)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel(ylabel)\n",
        "    return ax\n",
        "\n",
        "### Finalmente graficamos el summary plot que hallamos obtenido. \n",
        "summary_plot(mnist_results,\n",
        "             ax,\n",
        "             col='accuracy',\n",
        "             ylabel='Accuracy')\n",
        "ax.set_ylim([0.5, 1])\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_xticks(np.linspace(0, 30, 7).astype(int));\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c7021cd",
      "metadata": {},
      "source": [
        "Los resultados de esta regresión son comparados con los de la regresión logística. Por lo cuál en el mismo notebook se incluye una implementación de dicho modelo. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "93d9c001",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name  | Type             | Params | Mode \n",
            "---------------------------------------------------\n",
            "0 | model | MNIST_MLR        | 7.9 K  | train\n",
            "1 | loss  | CrossEntropyLoss | 0      | train\n",
            "---------------------------------------------------\n",
            "7.9 K     Trainable params\n",
            "0         Non-trainable params\n",
            "7.9 K     Total params\n",
            "0.031     Total estimated model params size (MB)\n",
            "5         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
          ]
        }
      ],
      "source": [
        "class MNIST_MLR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_MLR, self).__init__()\n",
        "        self.linear = nn.Sequential(nn.Flatten(),\n",
        "                                    nn.Linear(784, 10))\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "mlr_model = MNIST_MLR()\n",
        "mlr_module = SimpleModule.classification(mlr_model,\n",
        "                                         num_classes=10)\n",
        "mlr_logger = CSVLogger('logs', name='MNIST_MLR')\n",
        "\n",
        "mlr_trainer = Trainer(deterministic=True,\n",
        "                      max_epochs=30,\n",
        "                      enable_progress_bar=False,\n",
        "                      callbacks=[ErrorTracker()])\n",
        "mlr_trainer.fit(mlr_module, datamodule=mnist_dm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "8e355fe8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "      test_accuracy         0.9203000068664551\n",
            "        test_loss           0.33038607239723206\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'test_loss': 0.33038607239723206, 'test_accuracy': 0.9203000068664551}]"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlr_trainer.test(mlr_module,\n",
        "                 datamodule=mnist_dm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90a19b3a",
      "metadata": {},
      "source": [
        "Se encuentra entonces que los resultados de esta regresión loística logran tener un buen desempeño en los datos de prueba con un accuracy de cerca del 90%."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d03dc38b",
      "metadata": {},
      "source": [
        "### Referencias. \n",
        "\n",
        "Las referencias empleadas para el entranamiento de los notebooks. \n",
        "\n",
        "Building a Logistic Regression Classifier in Pytorch: https://machinelearningmastery.com/building-a-logistic-regression-classifier-in-pytorch/. \n",
        "\n",
        "Trebor, Hastie et AL. Deep Learning. Disponible en: https://colab.research.google.com/github/intro-stat-learning/ISLP_labs/blob/v2.2/Ch10-deeplearning-lab.ipynb#scrollTo=6ff23014\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "CEFA_2025_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
